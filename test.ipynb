{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bffef5c-f3c7-4ef8-9795-72e762abc730",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b06592b446749358160a84583605f92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# 模型和tokenizer的加载\n",
    "model_path = \"/root/autodl-tmp/new_model\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "text_generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_path,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b2d61cf-6dea-4e42-a25e-b9c252aeba7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# 加载数据集和prompt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessdata/testdata_dev.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m----> 4\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprompt.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      6\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mread()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# 加载数据集和prompt\n",
    "with open('processdata/testdata_dev.json', 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "with open('prompt.txt', 'r', encoding='utf-8') as file:\n",
    "    prompt = file.read()\n",
    "total_true_positive = 0\n",
    "total_predicted = 0\n",
    "total_actual = 0\n",
    "idx = 0\n",
    "data=data[:500]\n",
    "def compare_triples(predicted_triples, true_triples):\n",
    "    correct_count = 0\n",
    "    try:\n",
    "        true_triples_set = set(\n",
    "            f\"{triple['h']}|{triple['t']}|{triple['r']}\" for triple in true_triples\n",
    "        )\n",
    "        for pred in predicted_triples:\n",
    "            prediction_str = f\"{pred['h']}|{pred['t']}|{pred['r']}\"\n",
    "            if prediction_str in true_triples_set:\n",
    "                correct_count += 1\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while comparing triples: {e}\")\n",
    "\n",
    "    return correct_count\n",
    "for item in tqdm(data, desc=\"Processing items\"):\n",
    "    text = item['text']\n",
    "    true_triples = item['labels']\n",
    "    # print(f\"Item {idx + 1} of {len(data)}\")\n",
    "    idx += 1\n",
    "    prompts = prompt + f\"###input: {text} ###output: \"\n",
    "    predictions = text_generator(prompts, max_new_tokens = 3000, num_return_sequences=1)\n",
    "    prediction = predictions[0]['generated_text']\n",
    "    \n",
    "    prediction = prediction.replace(\"\\n\", \"\")\n",
    "    prediction = prediction.replace(\"Here's the triplet information organized in List of JSON format, as per your request:```\",\"\")\n",
    "    prediction = prediction.replace(\"```Note: The remaining seven triples cannot be supported or explained by the provided context or they might be incorrect interpretations.\", \"\")\n",
    "    prediction = prediction.replace(\"\\\": None\",\"\\\": \\\" \\\" \")\n",
    "    prediction = prediction.replace(\"Sure, here it is::\", \"\")\n",
    "    prediction = prediction.replace(\"Here is the information organized in a JSON format with the requested keys for each relational triplet:```\", \"\")\n",
    "    prediction = prediction.replace(\"]```\", \"]\")\n",
    "    prediction = prediction.replace(\"JSON Format:\",\"\")\n",
    "    prediction = prediction.replace(\"```[\", \"[\")\n",
    "    prediction = prediction.replace(\"```For each triplet, the JSON object includes:- head entity: the main entity in the relationship- tail entity: the secondary entity in the relationship- relation type: the type of relationship between the entities- reasoning: an explanation of the significance of the relationship- context: the relevant sentence in which the relationship is mentioned in the original document.\", \"\")\n",
    "    prediction = prediction.replace(\"Sure, here is the information organized in a list of JSON format:```\", \"\")\n",
    "    prediction = prediction.replace(\"Sure, here it is:\", \"\")\n",
    "    prediction = prediction.replace(\"Here is the information organized in a JSON format with the requested keys for each relational triplet:```\", \"\")\n",
    "    prediction = prediction.replace(\"]```\", \"]\")\n",
    "    prediction = prediction.replace(\"JSON Format:\",\"\")\n",
    "    prediction = prediction.replace(\"```[\", \"[\")\n",
    "    prediction = prediction.replace(\"```json{\",\"{\")\n",
    "    prediction = prediction.replace(\"```json\",\"\")\n",
    "    prediction = prediction.replace(\"}}]\",\"}]\")\n",
    "    prediction = prediction.replace(\"[    {\",\"[{\")\n",
    "    prediction = prediction.replace(\"[  {\",\"[{\")\n",
    "    prediction = prediction.replace(\"[ {\",\"[{\")\n",
    "    prediction = prediction.replace(\"} ]\",\"}]\")\n",
    "    prediction = prediction.replace(\"}  ]\",\"}]\")\n",
    "    prediction = prediction.replace(\"}   ]\",\"}]\")\n",
    "    prediction = prediction.replace(\"```json[\",\"[\")\n",
    "    prediction = prediction.replace(\"```json\",\"\")\n",
    "    # print(\"prediction: \\n\", prediction)\n",
    "    start_idx = prediction.find(\"###output:\") + len(\"###output:\")\n",
    "    # 找到第一个'['\n",
    "    start_json_idx = prediction.find(\"[\", start_idx)\n",
    "    # 找到第一个']'之后的位置\n",
    "    end_json_idx = prediction.find(\"]\", start_json_idx) + 1\n",
    "    if end_json_idx == 0: \n",
    "        if prediction[-1] != ']':\n",
    "            if prediction[-1] == '}':\n",
    "                prediction += ']'\n",
    "            else:\n",
    "                prediction += \"}]\"\n",
    "        end_json_idx = len(prediction)\n",
    "    json_str = prediction[start_json_idx:end_json_idx]\n",
    "    json_str = json_str.replace(\"'\", '\"').replace('\\\\\\\\\"', \"\\\\'\")\n",
    "    fixed_data = re.sub(r\"(?<!\\\\)'(?=[^'\\\"]*?[\\\":])\", '\"', json_str)\n",
    "    # print(\"json_str: \\n\", json_str)\n",
    "    try:\n",
    "        extracted_triples = json.loads(fixed_data)\n",
    "        num_correct = compare_triples(extracted_triples, true_triples)\n",
    "        total_true_positive += num_correct\n",
    "        total_predicted += len(extracted_triples)\n",
    "        total_actual += len(true_triples)\n",
    "        print(f\"Finish the {idx} item\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        # print(\"json_str: \\n\", fixed_data)\n",
    "        print(\"Failed to decode JSON from the extracted string:\", e)\n",
    "    \n",
    "    precision = total_true_positive / total_predicted if total_predicted > 0 else 0\n",
    "    recall = total_true_positive / total_actual if total_actual > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    print(f\"The {idx} score: Precision: {precision:.3f} Recall: {recall:.3f} F1 Score: {f1_score:.3f}\")\n",
    "print(\"Finish testing...\")\n",
    "print(f\"The {idx} score: Precision: {precision:.3f} Recall: {recall:.3f} F1 Score: {f1_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622dcb43-c948-4860-a96c-a63a444240b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
